{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroAlign - Test\n",
    "\n",
    "Unit testing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Config as config\n",
    "import Data as data\n",
    "\n",
    "\n",
    "bb11001 = data.Fasta(\"./data/BB11001.fasta\", gaps = True, contains_lower_case = True)\n",
    "bb11002 = data.Fasta(\"./data/BB11002.fasta\", gaps = True, contains_lower_case = True)\n",
    "bb11003 = data.Fasta(\"./data/BB11003.fasta\", gaps = True, contains_lower_case = True)\n",
    "\n",
    "def test_property(x, y):\n",
    "    assert x == y, \"should be \" + str(y) + \" but is \" + str(x)\n",
    "    \n",
    "def test_markers(s, lengths):\n",
    "    for seq, l in zip(s, lengths):\n",
    "        test_property(np.argmax(seq[0]), data.GAP_MARKER)\n",
    "        test_property(np.argmax(seq[1]), data.START_MARKER)\n",
    "        test_property(np.argmax(seq[l+2]), data.END_MARKER)\n",
    "        assert np.all(seq[(l+3):] == 0), \"invalid padding\"\n",
    "        \n",
    "aa_to_index = {aa : i for i, aa in enumerate(data.ALPHABET+[\"-\"])}\n",
    "def test_aminoacid(vec, aa):\n",
    "    test_property(np.argmax(vec), aa_to_index[aa.upper()])\n",
    "def test_sequence(seq, seq_ref):\n",
    "    for s,sr in zip(seq[2:], seq_ref):\n",
    "        test_aminoacid(s,sr)\n",
    "\n",
    "full_seq_1,_,_,_ = bb11001.one_hot_sequences()\n",
    "full_seq_2,_,_,_ = bb11002.one_hot_sequences()\n",
    "full_seq_3,_,_,_ = bb11003.one_hot_sequences()\n",
    "part_seq_1,_,_,_ = bb11001.one_hot_sequences([0,1])\n",
    "part_seq_2,_,_,_ = bb11002.one_hot_sequences([3,4,5])\n",
    "part_seq_3,_,_,_ = bb11003.one_hot_sequences([1,3])\n",
    "\n",
    "test_property(full_seq_1.shape[0], 4)\n",
    "test_property(full_seq_2.shape[0], 8)\n",
    "test_property(full_seq_3.shape[0], 4)\n",
    "test_property(part_seq_1.shape[0], 2)\n",
    "test_property(part_seq_2.shape[0], 3)\n",
    "test_property(part_seq_3.shape[0], 2)\n",
    "\n",
    "test_property(full_seq_1.shape[1], 94)\n",
    "test_property(part_seq_1.shape[1], 88)\n",
    "\n",
    "test_markers(full_seq_1, [83, 85, 91, 86])\n",
    "test_markers(full_seq_2, [58, 193, 83, 52, 83, 101, 134, 80])\n",
    "test_markers(full_seq_3, [446, 516, 504, 414])\n",
    "\n",
    "test_sequence(full_seq_1[0], \"gkgdpkkprgkmssyaffvqtsreehkkkhpdasvnfsefskkcserwktmsakekgkfedmakadkaryeremktyippkge\")\n",
    "test_sequence(full_seq_1[1], \"mqdrvkrpmnafivwsrdqrrkmalenprmrnseiskqlgyqwkmlteaekwpffqeaqklqamhrekypnykyrprrkakmlpk\")\n",
    "test_sequence(full_seq_1[2], \"mkklkkhpdfpkkpltpyfrffmekrakyaklhpemsnldltkilskkykelpekkkmkyiqdfqrekqefernlarfredhpdliqnakk\")\n",
    "test_sequence(full_seq_1[3], \"mhikkplnafmlymkemranvvaestlkesaainqilgrrwhalsreeqakyyelarkerqlhmqlypgwsardnygkkkkrkrek\")\n",
    "test_sequence(full_seq_2[0], \"nlfvalydfvasgdntlsitkgeklrvlgynhngewceaqtkngqgwvpsnyitpvns\")\n",
    "test_sequence(full_seq_2[1], \"plallldsslegefdlvqriiyevddpslpndegitalhnavcaghteivkflvqfgvnvnaadsdgwtplhcaascnnvqvckflvesgaavfamtysdmqtaadkceemeegytqcsqflygvqekmgimnkgviyalwdyepqnddelpmkegdcmtiihrededeiewwwarlndkegyvprnllglyp\")\n",
    "test_sequence(full_seq_2[2], \"aegyqyralydykkereedidlhlgdiltvnkgslvalgfsdgqearpeeigwlngynettgergdfpgtyveyigrkkispp\")\n",
    "test_sequence(full_seq_2[5], \"adrklcadqecshpismavalqdymapdcrfltihrgqvvyvfsklkgrgrlfwggsvqgdyygdlaarlgyfpssivredqtlkpgkvdvktdkwdfycq\")\n",
    "\n",
    "test_sequence(part_seq_1[0], \"gkgdpkkprgkmssyaffvqtsreehkkkhpdasvnfsefskkcserwktmsakekgkfedmakadkaryeremktyippkge\")\n",
    "test_sequence(part_seq_1[1], \"mqdrvkrpmnafivwsrdqrrkmalenprmrnseiskqlgyqwkmlteaekwpffqeaqklqamhrekypnykyrprrkakmlpk\")\n",
    "test_sequence(part_seq_3[0], \"mtvepfrnepietfqteearramrealrrvreefgrhyplyiggewvdtkermvslnpsapsevvgttakagkaeaeaaleaawkafktwkdwpqedrsrlllkaaalmrrrkreleatlvyevgknwveasadvaeaidfieyyaraalryrypavevvpypgednesfyvplgagvviapwnfpvaiftgmivgpvavgntviakpaedavvvgakvfeifheagfppgvvnflpgvgeevgaylvehprirfinftgslevglkiyeaagrlapgqtwfkrayvetggknaiivdetadfdlaaegvvvsaygfqgqkcsaasrliltqgayepvlervlkraerlsvgpaeenpdlgpvvsaeqerkvlsyieigknegqlvlggkrlegegyfiaptvftevppkariaqeeifgpvlsvirvkdfaealevandtpygltggvysrkrehlewarrefhvgnlyfnrkitgalvgvqpfggfklsgtnaktgaldylrlflemkavaerf\")\n",
    "test_sequence(part_seq_3[1], \"dellekakkvreawdvlrnattreknkaikkiaeklderrkeileanridvekarergvkeslvdrlalndkridexikacetviglkdpvgevidswvredglriarvrvpigpigiiyesrpnvtvettilalksgntillrggsdalnsnkaivsairealketeipessvefientdrslvlexirlreylslviprggyglisfvrdnatvpvletgvgnchifvdesadlkkavpviinaktqrpgtcnaaekllvhekiakeflpviveelrkhgvevrgcektreivpdvvpateddwpteyldliiaikvvknvdeaiehikkystghsesiltenysnakkfvseidaaavyvnastrftdggqfgfgaeigistqrfhargpvglrelttykfvvlgeyhvre\")\n",
    "\n",
    "\n",
    "input1, target1 = data.get_input_target_data(bb11001, [0,1,2,3], config.base_model)\n",
    "assert np.all(input1[\"sequences\"] == full_seq_1)\n",
    "input2, target2 = data.get_input_target_data(bb11002, list(range(8)), config.base_model)\n",
    "assert np.all(input2[\"sequences\"] == full_seq_2)\n",
    "input3, target3 = data.get_input_target_data(bb11002, [3,4,5], config.base_model)\n",
    "assert np.all(input3[\"sequences\"] == part_seq_2)\n",
    "\n",
    "def test_column(col, col_as_string):\n",
    "    counts = np.zeros(len(data.ALPHABET)+3)\n",
    "    for x in col_as_string:\n",
    "        counts[aa_to_index[x.upper()]] += 1\n",
    "    counts /= len(col_as_string)\n",
    "    assert np.all(np.isclose(col, counts)), \"column \" + col_as_string + \" has wrong distribution \" + str(col)\n",
    "    \n",
    "    \n",
    "test_property(np.argmax(input1[\"in_columns\"][0]), data.START_MARKER)\n",
    "test_column(input1[\"in_columns\"][1], \"--m-\")    \n",
    "test_column(input1[\"in_columns\"][2], \"--k-\")  \n",
    "test_column(input1[\"in_columns\"][3], \"--k-\")   \n",
    "test_column(input1[\"in_columns\"][4], \"g-l-\") \n",
    "test_column(input1[\"in_columns\"][11], \"pvpi\") \n",
    "test_column(input1[\"in_columns\"][12], \"rkkk\")  \n",
    "test_column(input1[\"in_columns\"][59], \"kkkq\") \n",
    "test_column(input1[\"in_columns\"][80], \"yyfw\") \n",
    "\n",
    "test_property(np.argmax(input2[\"in_columns\"][0]), data.START_MARKER) \n",
    "test_column(input2[\"in_columns\"][1], \"-p------\")         \n",
    "test_column(input2[\"in_columns\"][3], \"-a------\")      \n",
    "test_column(input2[\"in_columns\"][155], \"kelkarep\")    \n",
    "test_column(input2[\"in_columns\"][162], \"linwifil\")     \n",
    "test_column(input2[\"in_columns\"][163], \"ghkkpshk\")    \n",
    "test_column(input2[\"in_columns\"][166], \"-dl--nk-\")      \n",
    "\n",
    "test_property(np.argmax(input3[\"in_columns\"][0]), data.START_MARKER) \n",
    "test_column(input3[\"in_columns\"][1], \"--a\")         \n",
    "test_column(input3[\"in_columns\"][2], \"--d\")         \n",
    "test_column(input3[\"in_columns\"][3], \"--r\")         \n",
    "test_column(input3[\"in_columns\"][4], \"-tk\")        \n",
    "test_column(input3[\"in_columns\"][39], \"avv\")        \n",
    "test_column(input3[\"in_columns\"][40], \"kvv\")         \n",
    "test_column(input3[\"in_columns\"][45], \"gfk\")        \n",
    "test_column(input3[\"in_columns\"][46], \"-ql\")       \n",
    "test_column(input3[\"in_columns\"][48], \"--g\")     \n",
    "test_column(input3[\"in_columns\"][49], \"-p-\")    \n",
    "test_column(input3[\"in_columns\"][60], \"dvs\")   \n",
    "test_column(input3[\"in_columns\"][61], \"nkv\")   \n",
    "\n",
    "assert np.all(input1[\"in_columns\"][1:] == target1[\"out_columns\"][:-1])\n",
    "assert np.all(input2[\"in_columns\"][1:] == target2[\"out_columns\"][:-1])\n",
    "assert np.all(input3[\"in_columns\"][1:] == target3[\"out_columns\"][:-1])\n",
    "\n",
    "def test_attention1(seq, pos, target_column):\n",
    "    test_property(np.argmax(target1[\"out_attention\"][seq, pos]), target_column)\n",
    "    \n",
    "test_attention1(0,1,3)\n",
    "test_attention1(0,2,4)\n",
    "test_attention1(0,49,51)\n",
    "test_attention1(1,1,6)\n",
    "test_attention1(1,43,50)\n",
    "test_attention1(1,57,64)\n",
    "test_attention1(2,1,0)\n",
    "test_attention1(2,39,40)\n",
    "\n",
    "def test_attention3(seq, pos, target_column):\n",
    "    test_property(np.argmax(target3[\"out_attention\"][seq, pos]), target_column)\n",
    "    \n",
    "test_attention3(0,1,12)\n",
    "test_attention3(1,1,3)\n",
    "test_attention3(2,1,0)\n",
    "test_attention3(0,15,32)\n",
    "test_attention3(1,50,53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured model  uniform_seqs  and initialized weights randomly.\n",
      "[26  7 11  7  3 25 14 11 11 14  1 25  7 11 12 15 15 25 18  0 13 13 19 25\n",
      "  5 16 15  1  6 25  6  8 11 11 11 25  8 14  3  0 15 25 19  2 13 15  6 25\n",
      " 13 15 11 11  4 25 15  6  1 17 11 25 16 12 15  0 11 25  6 11  7 11 13 25\n",
      "  6  3 12  0 11 25  0  3 11  0  1 25 18  6  1  6 12 25 11 16 18  9 14 25\n",
      " 14 11  7  6 25 27]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import Data as data\n",
    "import Model as model\n",
    "import numpy as np\n",
    "\n",
    "neuroalign, neuroalign_config = model.make_neuro_align_model(\"uniform_seqs\")\n",
    "\n",
    "bb11001 = data.Fasta(\"./data/BB11001.fasta\", gaps = True, contains_lower_case = True)\n",
    "\n",
    "input_dict, target_dict = data.get_input_target_data(bb11001, list(range(len(bb11001.raw_seq))), neuroalign_config)\n",
    "\n",
    "print(np.argmax(input_dict[\"sequences\"][0], axis=-1))\n",
    "print(np.sum(target_dict[\"out_attention\"][0,:20,:], axis=-1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
