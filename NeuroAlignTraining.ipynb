{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroAlign - Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  2  GPU devices.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import Model as model\n",
    "import Data as data\n",
    "\n",
    "\n",
    "GPUS = tf.config.experimental.list_logical_devices('GPU')\n",
    "NUM_DEVICES = max(1, len(GPUS))\n",
    "\n",
    "if len(GPUS) > 0:\n",
    "    print(\"Using \", NUM_DEVICES, \" GPU devices.\")\n",
    "else:\n",
    "    print(\"Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured model  base2  and initialized weights randomly.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "NAME = \"base2\"\n",
    "MODEL_PATH = \"./models/\" + NAME\n",
    "CHECKPOINT_PATH = MODEL_PATH + \"/model.ckpt\"\n",
    "\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "neuroalign, neuroalign_config = model.make_neuro_align_model(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 % loaded\n",
      "20 % loaded\n",
      "30 % loaded\n",
      "40 % loaded\n",
      "50 % loaded\n",
      "60 % loaded\n",
      "70 % loaded\n",
      "80 % loaded\n",
      "90 % loaded\n",
      "Using the full dataset.\n"
     ]
    }
   ],
   "source": [
    "#Pfam protein families have identifiers of the form PF00001, PF00002, ...\n",
    "#The largest id is PF19227, but the counting is not contiguous, there may be missing numbers\n",
    "pfam = [\"PF\"+\"{0:0=5d}\".format(i) for i in range(1,19228)]\n",
    "pfam_not_found = 0\n",
    "\n",
    "fasta = []\n",
    "\n",
    "for i,file in enumerate(pfam):\n",
    "    try:\n",
    "        f = data.Fasta(\"../brain/Pfam/alignments/\" + file + \".fasta\", gaps = True, contains_lower_case = True)\n",
    "        fasta.append(f)\n",
    "        for x in range(1,10):\n",
    "            if i/len(pfam) > x/10 and (i-1)/len(pfam) < x/10:\n",
    "                print(x*10, \"% loaded\")\n",
    "                gc.collect()\n",
    "    except:\n",
    "        pfam_not_found += 1\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "indices = np.arange(len(fasta))\n",
    "np.random.shuffle(indices)\n",
    "if len(fasta) > 10:\n",
    "    print(\"Using the full dataset.\")\n",
    "    train, val = np.split(indices, [int(len(fasta)*(1-neuroalign_config[\"validation_split\"]))]) \n",
    "    train_gen = data.AlignmentSampleGenerator(train, fasta, neuroalign_config, neuroalign_config[\"family_size\"], NUM_DEVICES)\n",
    "    val_gen = data.AlignmentSampleGenerator(val, fasta, neuroalign_config, 2*neuroalign_config[\"family_size\"], NUM_DEVICES, False)\n",
    "else: \n",
    "    print(\"Using a small test dataset.\")\n",
    "    train_gen = data.AlignmentSampleGenerator(np.arange(len(fasta)), fasta, neuroalign_config, neuroalign_config[\"family_size\"], NUM_DEVICES)\n",
    "    val_gen = data.AlignmentSampleGenerator(np.arange(len(fasta)), fasta, neuroalign_config, 2*neuroalign_config[\"family_size\"], NUM_DEVICES, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0999 - GPU_0_out_columns_loss: 1.4899 - GPU_0_out_attention_loss: 0.0176 - GPU_1_out_columns_loss: 1.4528 - GPU_1_out_attention_loss: 0.0243Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2117s 122ms/step - loss: 0.0999 - GPU_0_out_columns_loss: 1.4899 - GPU_0_out_attention_loss: 0.0176 - GPU_1_out_columns_loss: 1.4528 - GPU_1_out_attention_loss: 0.0243 - val_loss: 0.0863 - val_GPU_0_out_columns_loss: 1.2567 - val_GPU_0_out_attention_loss: 0.0164 - val_GPU_1_out_columns_loss: 1.1811 - val_GPU_1_out_attention_loss: 0.0220\n",
      "Epoch 2/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0863 - GPU_0_out_columns_loss: 1.3287 - GPU_0_out_attention_loss: 0.0156 - GPU_1_out_columns_loss: 1.2103 - GPU_1_out_attention_loss: 0.0207Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2123s 122ms/step - loss: 0.0863 - GPU_0_out_columns_loss: 1.3287 - GPU_0_out_attention_loss: 0.0156 - GPU_1_out_columns_loss: 1.2103 - GPU_1_out_attention_loss: 0.0207 - val_loss: 0.0772 - val_GPU_0_out_columns_loss: 1.1472 - val_GPU_0_out_attention_loss: 0.0149 - val_GPU_1_out_columns_loss: 1.0176 - val_GPU_1_out_attention_loss: 0.0198\n",
      "Epoch 3/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0747 - GPU_0_out_columns_loss: 1.1178 - GPU_0_out_attention_loss: 0.0147 - GPU_1_out_columns_loss: 0.9615 - GPU_1_out_attention_loss: 0.0191Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2121s 122ms/step - loss: 0.0747 - GPU_0_out_columns_loss: 1.1178 - GPU_0_out_attention_loss: 0.0147 - GPU_1_out_columns_loss: 0.9615 - GPU_1_out_attention_loss: 0.0191 - val_loss: 0.0640 - val_GPU_0_out_columns_loss: 0.9306 - val_GPU_0_out_attention_loss: 0.0135 - val_GPU_1_out_columns_loss: 0.7698 - val_GPU_1_out_attention_loss: 0.0171\n",
      "Epoch 4/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0674 - GPU_0_out_columns_loss: 0.9944 - GPU_0_out_attention_loss: 0.0139 - GPU_1_out_columns_loss: 0.8364 - GPU_1_out_attention_loss: 0.0175Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2123s 122ms/step - loss: 0.0674 - GPU_0_out_columns_loss: 0.9944 - GPU_0_out_attention_loss: 0.0139 - GPU_1_out_columns_loss: 0.8364 - GPU_1_out_attention_loss: 0.0175 - val_loss: 0.0614 - val_GPU_0_out_columns_loss: 0.8838 - val_GPU_0_out_attention_loss: 0.0135 - val_GPU_1_out_columns_loss: 0.7243 - val_GPU_1_out_attention_loss: 0.0163\n",
      "Epoch 5/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0624 - GPU_0_out_columns_loss: 0.9198 - GPU_0_out_attention_loss: 0.0130 - GPU_1_out_columns_loss: 0.7607 - GPU_1_out_attention_loss: 0.0164Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2121s 122ms/step - loss: 0.0624 - GPU_0_out_columns_loss: 0.9198 - GPU_0_out_attention_loss: 0.0130 - GPU_1_out_columns_loss: 0.7607 - GPU_1_out_attention_loss: 0.0164 - val_loss: 0.0521 - val_GPU_0_out_columns_loss: 0.7125 - val_GPU_0_out_attention_loss: 0.0119 - val_GPU_1_out_columns_loss: 0.6003 - val_GPU_1_out_attention_loss: 0.0146\n",
      "Epoch 6/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0551 - GPU_0_out_columns_loss: 0.7976 - GPU_0_out_attention_loss: 0.0118 - GPU_1_out_columns_loss: 0.6693 - GPU_1_out_attention_loss: 0.0145Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2128s 123ms/step - loss: 0.0551 - GPU_0_out_columns_loss: 0.7976 - GPU_0_out_attention_loss: 0.0118 - GPU_1_out_columns_loss: 0.6693 - GPU_1_out_attention_loss: 0.0145 - val_loss: 0.0487 - val_GPU_0_out_columns_loss: 0.6678 - val_GPU_0_out_attention_loss: 0.0112 - val_GPU_1_out_columns_loss: 0.5560 - val_GPU_1_out_attention_loss: 0.0135\n",
      "Epoch 7/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0527 - GPU_0_out_columns_loss: 0.7549 - GPU_0_out_attention_loss: 0.0113 - GPU_1_out_columns_loss: 0.6405 - GPU_1_out_attention_loss: 0.0139Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2120s 122ms/step - loss: 0.0527 - GPU_0_out_columns_loss: 0.7549 - GPU_0_out_attention_loss: 0.0113 - GPU_1_out_columns_loss: 0.6405 - GPU_1_out_attention_loss: 0.0139 - val_loss: 0.0470 - val_GPU_0_out_columns_loss: 0.6420 - val_GPU_0_out_attention_loss: 0.0108 - val_GPU_1_out_columns_loss: 0.5472 - val_GPU_1_out_attention_loss: 0.0129\n",
      "Epoch 8/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0507 - GPU_0_out_columns_loss: 0.7351 - GPU_0_out_attention_loss: 0.0109 - GPU_1_out_columns_loss: 0.6185 - GPU_1_out_attention_loss: 0.0133Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2129s 123ms/step - loss: 0.0507 - GPU_0_out_columns_loss: 0.7351 - GPU_0_out_attention_loss: 0.0109 - GPU_1_out_columns_loss: 0.6185 - GPU_1_out_attention_loss: 0.0133 - val_loss: 0.0459 - val_GPU_0_out_columns_loss: 0.6613 - val_GPU_0_out_attention_loss: 0.0100 - val_GPU_1_out_columns_loss: 0.5228 - val_GPU_1_out_attention_loss: 0.0126\n",
      "Epoch 9/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0493 - GPU_0_out_columns_loss: 0.7169 - GPU_0_out_attention_loss: 0.0106 - GPU_1_out_columns_loss: 0.6023 - GPU_1_out_attention_loss: 0.0128Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2128s 123ms/step - loss: 0.0493 - GPU_0_out_columns_loss: 0.7169 - GPU_0_out_attention_loss: 0.0106 - GPU_1_out_columns_loss: 0.6023 - GPU_1_out_attention_loss: 0.0128 - val_loss: 0.0440 - val_GPU_0_out_columns_loss: 0.6307 - val_GPU_0_out_attention_loss: 0.0100 - val_GPU_1_out_columns_loss: 0.5117 - val_GPU_1_out_attention_loss: 0.0116\n",
      "Epoch 10/200\n",
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0486 - GPU_0_out_columns_loss: 0.7018 - GPU_0_out_attention_loss: 0.0105 - GPU_1_out_columns_loss: 0.5944 - GPU_1_out_attention_loss: 0.0127Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2136s 123ms/step - loss: 0.0486 - GPU_0_out_columns_loss: 0.7018 - GPU_0_out_attention_loss: 0.0105 - GPU_1_out_columns_loss: 0.5944 - GPU_1_out_attention_loss: 0.0127 - val_loss: 0.0438 - val_GPU_0_out_columns_loss: 0.6278 - val_GPU_0_out_attention_loss: 0.0100 - val_GPU_1_out_columns_loss: 0.4995 - val_GPU_1_out_attention_loss: 0.0117\n",
      "Epoch 11/200\n",
      "16863/17346 [============================>.] - ETA: 56s - loss: 0.0475 - GPU_0_out_columns_loss: 0.6909 - GPU_0_out_attention_loss: 0.0103 - GPU_1_out_columns_loss: 0.5796 - GPU_1_out_attention_loss: 0.0123Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2134s 123ms/step - loss: 0.0475 - GPU_0_out_columns_loss: 0.6906 - GPU_0_out_attention_loss: 0.0103 - GPU_1_out_columns_loss: 0.5795 - GPU_1_out_attention_loss: 0.0123 - val_loss: 0.0436 - val_GPU_0_out_columns_loss: 0.6329 - val_GPU_0_out_attention_loss: 0.0101 - val_GPU_1_out_columns_loss: 0.4947 - val_GPU_1_out_attention_loss: 0.0114\n",
      "Epoch 12/200\n",
      " 2720/17346 [===>..........................] - ETA: 28:07 - loss: 0.0475 - GPU_0_out_columns_loss: 0.6914 - GPU_0_out_attention_loss: 0.0102 - GPU_1_out_columns_loss: 0.5772 - GPU_1_out_attention_loss: 0.0123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16862/17346 [============================>.] - ETA: 55s - loss: 0.0469 - GPU_0_out_columns_loss: 0.6747 - GPU_0_out_attention_loss: 0.0102 - GPU_1_out_columns_loss: 0.5709 - GPU_1_out_attention_loss: 0.0122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13173/17346 [=====================>........] - ETA: 8:08 - loss: 0.0464 - GPU_0_out_columns_loss: 0.6736 - GPU_0_out_attention_loss: 0.0100 - GPU_1_out_columns_loss: 0.5650 - GPU_1_out_attention_loss: 0.0120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9020/17346 [==============>...............] - ETA: 16:08 - loss: 0.0458 - GPU_0_out_columns_loss: 0.6595 - GPU_0_out_attention_loss: 0.0101 - GPU_1_out_columns_loss: 0.5562 - GPU_1_out_attention_loss: 0.0118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11256/17346 [==================>...........] - ETA: 11:49 - loss: 0.0459 - GPU_0_out_columns_loss: 0.6618 - GPU_0_out_attention_loss: 0.0101 - GPU_1_out_columns_loss: 0.5578 - GPU_1_out_attention_loss: 0.0119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6310/17346 [=========>....................] - ETA: 21:22 - loss: 0.0456 - GPU_0_out_columns_loss: 0.6591 - GPU_0_out_attention_loss: 0.0099 - GPU_1_out_columns_loss: 0.5556 - GPU_1_out_attention_loss: 0.0119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8919/17346 [==============>...............] - ETA: 16:23 - loss: 0.0456 - GPU_0_out_columns_loss: 0.6615 - GPU_0_out_attention_loss: 0.0098 - GPU_1_out_columns_loss: 0.5563 - GPU_1_out_attention_loss: 0.0119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6673/17346 [==========>...................] - ETA: 20:47 - loss: 0.0447 - GPU_0_out_columns_loss: 0.6453 - GPU_0_out_attention_loss: 0.0098 - GPU_1_out_columns_loss: 0.5512 - GPU_1_out_attention_loss: 0.0115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3347/17346 [====>.........................] - ETA: 27:24 - loss: 0.0450 - GPU_0_out_columns_loss: 0.6625 - GPU_0_out_attention_loss: 0.0095 - GPU_1_out_columns_loss: 0.5550 - GPU_1_out_attention_loss: 0.0116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4310/17346 [======>.......................] - ETA: 25:24 - loss: 0.0447 - GPU_0_out_columns_loss: 0.6552 - GPU_0_out_attention_loss: 0.0095 - GPU_1_out_columns_loss: 0.5513 - GPU_1_out_attention_loss: 0.0115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17346/17346 [==============================] - ETA: 0s - loss: 0.0444 - GPU_0_out_columns_loss: 0.6444 - GPU_0_out_attention_loss: 0.0095 - GPU_1_out_columns_loss: 0.5464 - GPU_1_out_attention_loss: 0.0114Saved model to ./models/base2/model.ckpt\n",
      "17346/17346 [==============================] - 2119s 122ms/step - loss: 0.0444 - GPU_0_out_columns_loss: 0.6444 - GPU_0_out_attention_loss: 0.0095 - GPU_1_out_columns_loss: 0.5464 - GPU_1_out_attention_loss: 0.0114 - val_loss: 0.0411 - val_GPU_0_out_columns_loss: 0.5614 - val_GPU_0_out_attention_loss: 0.0097 - val_GPU_1_out_columns_loss: 0.4720 - val_GPU_1_out_attention_loss: 0.0111\n",
      "Epoch 18/200\n",
      "  653/17346 [>.............................] - ETA: 32:43 - loss: 0.0444 - GPU_0_out_columns_loss: 0.6544 - GPU_0_out_attention_loss: 0.0094 - GPU_1_out_columns_loss: 0.5377 - GPU_1_out_attention_loss: 0.0115"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 28\n",
    "\n",
    "COLUMN_LOSS_WEIGHT = 0.02\n",
    "ATTENTION_LOSS_WEIGHT = 0.98\n",
    "SEQUENCE_LOSS_WEIGHT = 1\n",
    "\n",
    "POS_WEIGHT = 1\n",
    "NEG_WEIGHT = 1\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(neuroalign_config[\"col_dim\"], tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(CustomSchedule(), beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "#loss for aligned aminoacid pairs (= attention)\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "     \n",
    "def make_mask(y_true):\n",
    "    mask = tf.math.equal(y_true, 0)\n",
    "    mask = tf.math.reduce_all(mask, axis=-1)\n",
    "    mask = tf.cast(tf.math.logical_not(mask), y_true.dtype)\n",
    "    return mask\n",
    "\n",
    "def make_sq(y, mask):\n",
    "    y = tf.boolean_mask(y, mask)\n",
    "    y_sq = tf.matmul(y, y, transpose_b=True)\n",
    "    y_sq = tf.reshape(y_sq, (-1, 1))\n",
    "    y_sq = tf.clip_by_value(y_sq, 0.0, 1.0)\n",
    "    return y_sq\n",
    "\n",
    "def att_loss(y_true, y_pred):\n",
    "    mask = make_mask(y_true)\n",
    "    y_true_sq = make_sq(y_true, mask)\n",
    "    y_pred_sq = make_sq(y_pred, mask)\n",
    "    l = tf.expand_dims(bce(y_true_sq, y_pred_sq), -1)\n",
    "    w = POS_WEIGHT * y_true_sq + NEG_WEIGHT * (1-y_true_sq)\n",
    "    l *= w\n",
    "    return tf.reduce_sum(l) / tf.reduce_sum(w)\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "#loss for sequence reconstruction from columns (unsupervised)\n",
    "\n",
    "ce = keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "def seq_loss(y_true, y_pred):\n",
    "    mask = make_mask(y_true)\n",
    "    l = ce(y_true, y_pred) * mask\n",
    "    return tf.math.reduce_sum(l) / tf.math.reduce_sum(mask)\n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "#precision and recall metrics for aligned aminoacid pairs\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    mask = make_mask(y_true)\n",
    "    y_true_sq = make_sq(y_true, mask)\n",
    "    y_pred_sq = make_sq(y_pred, mask)\n",
    "    positives = tf.cast(y_pred_sq >= threshold, tf.float32) \n",
    "    true_positives = positives * y_true_sq\n",
    "    precision = tf.reduce_sum(true_positives) / tf.math.maximum(tf.reduce_sum(positives), 1.0)\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    mask = make_mask(y_true)\n",
    "    y_true_sq = make_sq(y_true, mask)\n",
    "    y_pred_sq = make_sq(y_pred, mask)\n",
    "    positives = tf.cast(y_pred_sq >= threshold, tf.float32)\n",
    "    true_positives = positives * y_true_sq\n",
    "    recall = tf.reduce_sum(true_positives) / tf.math.maximum(tf.reduce_sum(y_true_sq), 1.0)\n",
    "    return recall\n",
    "\n",
    "#categorical accuracy for reconstructed sequences\n",
    "\n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    mask = make_mask(y_true)\n",
    "    acc = tf.equal(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1)) \n",
    "    acc = tf.cast(acc, dtype=y_true.dtype)\n",
    "    return tf.math.reduce_sum(acc * mask) / tf.math.reduce_sum(mask)\n",
    "    \n",
    "\n",
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "def losses_prefixed(losses, metrics, weights, prefix=\"\"):\n",
    "    if neuroalign_config[\"use_column_loss\"]:\n",
    "        losses.update({prefix+\"out_columns\" : tf.keras.losses.KLDivergence()})\n",
    "        weights.update({prefix+\"out_columns\" : COLUMN_LOSS_WEIGHT})\n",
    "    if neuroalign_config[\"use_attention_loss\"]:\n",
    "        losses.update({prefix+\"out_attention\" : att_loss})\n",
    "        metrics.update({prefix+\"out_attention\" : []})\n",
    "        weights.update({prefix+\"out_attention\" : ATTENTION_LOSS_WEIGHT})\n",
    "        \n",
    "\n",
    "losses, metrics, weights = {}, {}, {}\n",
    "if NUM_DEVICES == 1:\n",
    "    model = neuroalign\n",
    "    losses_prefixed(losses, metrics, weights)\n",
    "else:\n",
    "    inputs, outputs = [], []\n",
    "    for i, gpu in enumerate(GPUS):\n",
    "        with tf.device(gpu.name):\n",
    "            sequences = keras.Input(shape=(None,INPUT_DIM), name=\"GPU_\"+str(i)+\"_sequences\")\n",
    "            columns = keras.Input(shape=(INPUT_DIM), name=\"GPU_\"+str(i)+\"_in_columns\")\n",
    "            input_dict = {  \"sequences\" : sequences,\n",
    "                            \"in_columns\" : columns }\n",
    "            out_cols, A = neuroalign(input_dict)\n",
    "            outputs.append(layers.Lambda(lambda x: x, name=\"GPU_\"+str(i)+\"_out_columns\")(out_cols))\n",
    "            outputs.append(layers.Lambda(lambda x: x, name=\"GPU_\"+str(i)+\"_out_attention\")(A))\n",
    "            inputs.extend([sequences, columns])\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    for i, gpu in enumerate(GPUS):\n",
    "        losses_prefixed(losses, metrics, weights, \"GPU_\"+str(i)+\"_\")\n",
    "\n",
    "model.compile(loss=losses, optimizer=optimizer, metrics=metrics, loss_weights=weights)\n",
    "    \n",
    "class ModelCheckpoint(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        neuroalign.save_weights(CHECKPOINT_PATH)\n",
    "        print(\"Saved model to \" + CHECKPOINT_PATH, flush=True)\n",
    "\n",
    "csv_logger = CSVLogger(MODEL_PATH + \"/log.csv\", append=True, separator=',')\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs = NUM_EPOCHS,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[ModelCheckpoint(), csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
